{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3 - Example of submission \n",
    "We randomly generates annotations for the dev set. \n",
    "It is assumed that the folder \"dev\" is in the same folder as this notebook. Moreover, it is assumed that the file \"propaganda-techniques-names.txt\" is also in the same folder as the notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_folder = \"dev\" # if dev folder and propaganda-techniques-names.txt are not in the same folder as this \n",
    "propaganda_techniques_file = \"propaganda-techniques-names.txt\" # notebook, change these variables accordingly\n",
    "\n",
    "import glob\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "\n",
    "regex = re.compile(\"article([0-9]+).*\") # regular expression for extracting article id from file name\n",
    "random.seed(10) # to make runs deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading training data and the list of technique names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading articles' content from *.txt files in the dev folder\n",
    "file_list = glob.glob(os.path.join(dev_folder, \"*.txt\"))\n",
    "articles_content, articles_id = ([], [])\n",
    "for filename in file_list:\n",
    "    with open(filename, \"r\") as f:  \n",
    "        articles_content.append(f.read())\n",
    "        articles_id.append(regex.match(os.path.basename(filename)).group(1)) # extract article id from file name\n",
    "\n",
    "with open(propaganda_techniques_file, \"r\") as f:\n",
    "    propaganda_techniques_names = [ line.rstrip() for line in f.readlines() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate random fragments and save them in the output format for the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"example-submission-task3-predictions.txt\", \"w\") as fout:\n",
    "    for article_content, article_id in zip(articles_content, articles_id):\n",
    "        start_fragment, end_fragment, article_length = (0, 0, len(article_content))\n",
    "        current_article_annotations = []\n",
    "        while end_fragment < article_length:\n",
    "            if end_fragment > 0:\n",
    "                technique_name = propaganda_techniques_names[random.randint(0, len(propaganda_techniques_names)-1)]\n",
    "                # check that there is no other annotation for the same article and technique that overlaps\n",
    "                intersection_length = 0\n",
    "                if len(current_article_annotations) > 0:\n",
    "                    span_annotation = set(range(start_fragment, end_fragment))\n",
    "                    intersection_length = sum( [ len(span_annotation.intersection(previous_fragment))\n",
    "                             for previous_technique, previous_fragment in current_article_annotations \n",
    "                             if previous_technique==technique_name ])\n",
    "                if len(current_article_annotations) == 0 or intersection_length > 0:\n",
    "                    fout.write(\"%s\\t%s\\t%s\\t%s\\n\" % (article_id, technique_name, start_fragment, end_fragment))\n",
    "                    current_article_annotations.append((technique_name, set(range(start_fragment, end_fragment))))\n",
    "            start_fragment += random.randint(0, max(1, article_length-start_fragment))\n",
    "            end_fragment = min(start_fragment + random.randint(1,25), article_length)\n",
    "        #print(\"article %s: added %d fragments\" % (article_id, len(current_article_annotations)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the scorer on file \"example-submission-task3-predictions.txt\" gives the following results:\n",
    "\n",
    "Precision=0.003968\n",
    "Recall=0.000240\n",
    "F1=0.000452"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
