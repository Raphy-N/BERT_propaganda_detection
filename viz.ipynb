{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T09:26:43.058845Z",
     "start_time": "2019-04-10T09:26:42.900781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tools.task3_scorer_onefile\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_pretrained_bert import (BasicTokenizer, BertConfig,\n",
    "                                     BertForTokenClassification, BertTokenizer)\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, warmup_linear\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as f1\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, WeightedRandomSampler, TensorDataset\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import trange\n",
    "import os \n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_logger() -> None:\n",
    "    if not os.path.exists(\"./exp/{}/{}\".format(opt[\"classType\"], opt[\"expID\"])):\n",
    "            try:\n",
    "                os.mkdir(\"./exp/{}/{}\".format(opt[\"classType\"], opt[\"expID\"]))\n",
    "            except FileNotFoundError:\n",
    "                os.mkdir(\"./exp/{}\".format(opt[\"classType\"]))\n",
    "                os.mkdir(\"./exp/{}/{}\".format(opt[\"classType\"], opt[\"expID\"]))\n",
    "    \n",
    "    logging.basicConfig(\n",
    "    filename= (\"./exp/{}/{}/log.txt\".format(opt[\"classType\"], opt[\"expID\"])),\n",
    "    filemode='a',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s, %(message)s')\n",
    "\n",
    "    logging.getLogger().addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(\n",
    "            model.state_dict(), './exp/{}/{}/best_model.pth'.format(opt[\"classType\"], opt[\"expID\"]))\n",
    "        #torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T08:58:55.600576Z",
     "start_time": "2019-04-09T08:58:54.954119Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import ast\n",
    "from utils import *\n",
    "\n",
    "\n",
    "def pad_sequences(sequences: list, batch_first: bool = True, padding_value: int = 0, max_len: int = 0):\n",
    "    tmp = torch.Tensor(sequences[0])\n",
    "    max_size = tmp.size()\n",
    "    trailing_dims = max_size[1:]\n",
    "    \n",
    "    if batch_first:\n",
    "        out_dims = (len(sequences), max_len) + trailing_dims\n",
    "    else:\n",
    "        out_dims = (max_len, len(sequences)) + trailing_dims\n",
    "\n",
    "    out_tensor = tmp.data.new(*out_dims).fill_(padding_value)\n",
    "    for i, list in enumerate(sequences):\n",
    "        tensor = torch.Tensor(list)\n",
    "        length = tensor.size(0)\n",
    "        if batch_first:\n",
    "            out_tensor[i, :length, ...] = tensor\n",
    "        else:\n",
    "            out_tensor[:length, i, ...] = tensor\n",
    "\n",
    "    return out_tensor.long().numpy()\n",
    "\n",
    "# def set_global_label(bio: bool = False) -> None:\n",
    "#     global hash_token\n",
    "#     global end_token \n",
    "#     if bio:\n",
    "#         hash_token = 3\n",
    "#         end_token = 4\n",
    "#     else:\n",
    "#         hash_token = 2\n",
    "#         end_token = 3\n",
    "\n",
    "def reg_encoding(cleaned: list, labels: list, hash_token, end_token) -> list:\n",
    "    label_l = []\n",
    "    for oindex, x in enumerate(cleaned):\n",
    "        tlist = []\n",
    "        for index, j in enumerate(x):\n",
    "            for s in j:\n",
    "                if s[0]=='#':\n",
    "                    tlist.append(hash_token)\n",
    "                else:\n",
    "                    tlist.append(labels[oindex][index])\n",
    "        label_l.append(tlist)\n",
    "    return label_l\n",
    "\n",
    "def bio_encoding(cleaned: list, labels: list) -> list:\n",
    "    offset = 1\n",
    "    \n",
    "    label_l = []\n",
    "    for oindex, x in enumerate(cleaned):\n",
    "        tlist = []\n",
    "        prev=labels[oindex][0]\n",
    "        for index, j in enumerate(x):\n",
    "            #if index==30:\n",
    "            #ipdb.set_trace()\n",
    "            for s in j:\n",
    "                if s[0]=='#':\n",
    "                    tlist.append(hash_token)\n",
    "                else:\n",
    "                    if (index==0 and labels[oindex][index]!=0):\n",
    "                        tlist.append(labels[oindex][index]+offset)\n",
    "                        prev = labels[oindex][index]\n",
    "                    if (prev!=labels[oindex][index] and labels[oindex][index]!= 0):\n",
    "                        tlist.append(labels[oindex][index]+offset)\n",
    "                        prev = labels[oindex][index]\n",
    "                    else:\n",
    "                        tlist.append(labels[oindex][index])\n",
    "                        prev = labels[oindex][index]\n",
    "        label_l.append(tlist)\n",
    "    return label_l\n",
    "\n",
    "def concatenate_list_data(cleaned: list) -> list:\n",
    "    result= []\n",
    "    for element in cleaned:\n",
    "        result += element\n",
    "    return result\n",
    "\n",
    "def make_set(p2id, data_dir: str, tokenizer, single_class: str, \n",
    "             hash_token, end_token, bio: bool = False) -> list: \n",
    "    #dataset = pd.read_csv(data_dir, sep='\\t', header=None, converters={1:ast.literal_eval, 2:ast.literal_eval})\n",
    "    data_dict = pickle.load(open(data_dir, \"rb\"))\n",
    "    \n",
    "    dataset = corpus2list(p2id, data_dict[\"ID\"], data_dict[\"Text\"],\n",
    "                              data_dict[\"Label\"], single_class, bio)\n",
    "    # Shuffle samples\n",
    "    #dataset = dataset.sample(frac=1)\n",
    "    terms = list(dataset[1])\n",
    "    labels = list(dataset[2])\n",
    "    \n",
    "    cleaned = [[tokenizer.tokenize(words) for words in sent] for sent in terms]\n",
    "    tokenized_texts = [concatenate_list_data(sent) for sent in cleaned]\n",
    "    if bio:\n",
    "        label_l = bio_encoding(cleaned, labels)\n",
    "    else:\n",
    "        label_l = reg_encoding(cleaned, labels, hash_token, end_token)\n",
    "\n",
    "    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          padding_value=0.0, max_len=opt[\"maxLen\"])\n",
    "    \n",
    "    tags = pad_sequences(label_l, padding_value=end_token, max_len=opt[\"maxLen\"])\n",
    "    attention_masks = [[float(i>0) for i in ii] for ii in input_ids]\n",
    "    \n",
    "    \n",
    "    return input_ids, tags, attention_masks, label_l\n",
    "\n",
    "\n",
    "def make_val_set(p2id, data_dir: str, tokenizer, single_class: str, \n",
    "             hash_token, end_token, bio: bool = False) -> list: \n",
    "    #dataset = pd.read_csv(data_dir, sep='\\t', header=None, converters={1:ast.literal_eval, 2:ast.literal_eval})\n",
    "    data_dict = pickle.load(open(data_dir, \"rb\"))\n",
    "    if not bio:\n",
    "        dataset = corpus2list(p2id, data_dict[\"ID\"], data_dict[\"Text\"],\n",
    "                              data_dict[\"Label\"], single_class, bio)\n",
    "    # Shuffle samples\n",
    "    #dataset = dataset.sample(frac=1)\n",
    "    ids = (dataset[0])\n",
    "    terms = (dataset[1])\n",
    "    labels = (dataset[2])\n",
    "    spacy = (dataset[3])\n",
    "    cleaned = [[tokenizer.tokenize(words) for words in sent] for sent in terms]\n",
    "    tokenized_texts = [concatenate_list_data(sent) for sent in cleaned]\n",
    "\n",
    "    if bio:\n",
    "        label_l = bio_encoding(cleaned, labels)\n",
    "    else:\n",
    "        label_l = reg_encoding(cleaned, labels, hash_token, end_token)\n",
    "\n",
    "    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          padding_value=0.0, max_len=opt[\"maxLen\"])\n",
    "    \n",
    "    tags = pad_sequences(label_l, padding_value=end_token, max_len=opt[\"maxLen\"])\n",
    "    attention_masks = [[float(i>0) for i in ii] for ii in input_ids]\n",
    "    \n",
    "    \n",
    "    return input_ids, tags, attention_masks, cleaned, ids, terms, spacy, label_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    \"techniques\" : \"tools/data/propaganda-techniques-names.txt\",\n",
    "    \"binaryLabel\" : False,\n",
    "    \"nLabels\" : 21,\n",
    "    \"lowerCase\" : False,\n",
    "    \"bio\" : False,\n",
    "    \"model\" : \"bert-base-cased\",\n",
    "    \"trainDataset\" : \"train.p\",\n",
    "    \"evalDataset\" : \"test.p\",\n",
    "    \"trainBatch\" :16,\n",
    "    \"nEpochs\" :5,\n",
    "    \"LR\" :3e-5,\n",
    "    \"loadModel\" : \"exp/all_class/all_class_proper/4/model_4.pth\",\n",
    "    \"expID\" :\"spacy_viz\",\n",
    "    \"classType\" : \"all_class\",\n",
    "    \"testData\" : \"datasets-v5\",\n",
    "    \"train\" : True,\n",
    "    \"maxLen\" : 210,\n",
    "    \"patience\" : 2,\n",
    "    \"testDataset\" : \"datasets-v5/tasks-2-3/test\",\n",
    "    \"snapshot\" : 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_4.pth  optimizer.pth  option.pth  pred.tasks-2-3  score.tasks-2-3\r\n"
     ]
    }
   ],
   "source": [
    "ls exp/all_class/all_class_proper/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task2(predictions):\n",
    "    preddi = []\n",
    "    found = False\n",
    "    for x in predictions:\n",
    "        for j in x:\n",
    "            if j==1:\n",
    "                preddi.append(1)\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            preddi.append(0)\n",
    "        found = False\n",
    "    return preddi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T15:56:43.612181Z",
     "start_time": "2019-03-16T15:56:43.605658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 20\n",
      "{'O': 0, 'Appeal_to_Authority': 1, 'Appeal_to_fear-prejudice': 2, 'Bandwagon': 3, 'Black-and-White_Fallacy': 4, 'Causal_Oversimplification': 5, 'Doubt': 6, 'Exaggeration,Minimisation': 7, 'Flag-Waving': 8, 'Loaded_Language': 9, 'Name_Calling,Labeling': 10, 'Obfuscation,Intentional_Vagueness,Confusion': 11, 'Red_Herring': 12, 'Reductio_ad_hitlerum': 13, 'Repetition': 14, 'Slogans': 15, 'Straw_Men': 16, 'Thought-terminating_Cliches': 17, 'Whataboutism': 18}\n",
      "{'O': 0, 'Appeal_to_Authority': 1, 'Appeal_to_fear-prejudice': 2, 'Bandwagon': 3, 'Black-and-White_Fallacy': 4, 'Causal_Oversimplification': 5, 'Doubt': 6, 'Exaggeration,Minimisation': 7, 'Flag-Waving': 8, 'Loaded_Language': 9, 'Name_Calling,Labeling': 10, 'Obfuscation,Intentional_Vagueness,Confusion': 11, 'Red_Herring': 12, 'Reductio_ad_hitlerum': 13, 'Repetition': 14, 'Slogans': 15, 'Straw_Men': 16, 'Thought-terminating_Cliches': 17, 'Whataboutism': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fddba6a379c405d9470eb33cbdbe8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=870, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f3bc71a8e6416aabed0afe2ddab8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=128, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Counter check:  0\n",
      "{'submission': 'exp/all_class/spacy_viz/temp_pred.csv', 'gold': 'datasets-v5/tasks-2-3/test', 'debug_on_std': False, 'techniques_file': 'tools/data/propaganda-techniques-names.txt', 'log_file': 'exp/all_class/spacy_viz/temp_score.csv', 'fragments_only': False}\n",
      "2019-06-19 08:50:46,250 - INFO - Logging execution to file exp/all_class/spacy_viz/temp_score.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Logging execution to file exp/all_class/spacy_viz/temp_score.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,252 - INFO - Checking user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold folder datasets-v5/tasks-2-3/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Checking user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold folder datasets-v5/tasks-2-3/test\n",
      "DEBUG:propaganda_scorer:OK: all article ids have a correspondence in the list of articles from the reference dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,267 - INFO - Scoring user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold file datasets-v5/tasks-2-3/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Scoring user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold file datasets-v5/tasks-2-3/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,271 - INFO - Precision=12.558933/41=0.306315\tRecall=12.558933/927=0.013548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Precision=12.558933/41=0.306315\tRecall=12.558933/927=0.013548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,272 - INFO - F1=0.025948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:F1=0.025948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,275 - INFO - Appeal_to_Authority: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Appeal_to_Authority: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,276 - INFO - Appeal_to_fear-prejudice: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Appeal_to_fear-prejudice: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,278 - INFO - Bandwagon: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Bandwagon: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,279 - INFO - Black-and-White_Fallacy: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Black-and-White_Fallacy: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,280 - INFO - Causal_Oversimplification: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Causal_Oversimplification: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,282 - INFO - Doubt: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Doubt: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,284 - INFO - Exaggeration,Minimisation: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Exaggeration,Minimisation: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,285 - INFO - Flag-Waving: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Flag-Waving: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,286 - INFO - Loaded_Language: P=0.338505 R=0.036746 F1=0.066295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Loaded_Language: P=0.338505 R=0.036746 F1=0.066295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,287 - INFO - Name_Calling,Labeling: P=0.173532 R=0.009015 F1=0.017139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Name_Calling,Labeling: P=0.173532 R=0.009015 F1=0.017139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,290 - INFO - Obfuscation,Intentional_Vagueness,Confusion: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Obfuscation,Intentional_Vagueness,Confusion: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,291 - INFO - Red_Herring: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Red_Herring: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,293 - INFO - Reductio_ad_hitlerum: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Reductio_ad_hitlerum: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,295 - INFO - Repetition: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Repetition: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,296 - INFO - Slogans: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Slogans: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,298 - INFO - Straw_Men: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Straw_Men: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,299 - INFO - Thought-terminating_Cliches: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Thought-terminating_Cliches: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:50:46,301 - INFO - Whataboutism: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Whataboutism: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025948208538716742\n",
      "Validation loss decreased (inf --> -0.025948).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20%|██        | 1/5 [08:50<35:22, 530.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e9e46afbaf435bad366d7d9a3b92da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=870, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058a5162e57542ddafe7c44e681691f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=128, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Counter check:  0\n",
      "{'submission': 'exp/all_class/spacy_viz/temp_pred.csv', 'gold': 'datasets-v5/tasks-2-3/test', 'debug_on_std': False, 'techniques_file': 'tools/data/propaganda-techniques-names.txt', 'log_file': 'exp/all_class/spacy_viz/temp_score.csv', 'fragments_only': False}\n",
      "2019-06-19 08:59:39,433 - INFO - Logging execution to file exp/all_class/spacy_viz/temp_score.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Logging execution to file exp/all_class/spacy_viz/temp_score.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,436 - INFO - Checking user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold folder datasets-v5/tasks-2-3/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Checking user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold folder datasets-v5/tasks-2-3/test\n",
      "DEBUG:propaganda_scorer:OK: all article ids have a correspondence in the list of articles from the reference dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,450 - INFO - Scoring user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold file datasets-v5/tasks-2-3/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Scoring user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold file datasets-v5/tasks-2-3/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,463 - INFO - Precision=55.042153/316=0.174184\tRecall=55.042153/927=0.059377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Precision=55.042153/316=0.174184\tRecall=55.042153/927=0.059377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,465 - INFO - F1=0.088563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:F1=0.088563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,466 - INFO - Appeal_to_Authority: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Appeal_to_Authority: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,468 - INFO - Appeal_to_fear-prejudice: P=0.030016 R=0.043293 F1=0.035452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Appeal_to_fear-prejudice: P=0.030016 R=0.043293 F1=0.035452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,469 - INFO - Bandwagon: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Bandwagon: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,470 - INFO - Black-and-White_Fallacy: P=0.194744 R=0.113601 F1=0.143496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Black-and-White_Fallacy: P=0.194744 R=0.113601 F1=0.143496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,472 - INFO - Causal_Oversimplification: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Causal_Oversimplification: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,473 - INFO - Doubt: P=0.054472 R=0.018699 F1=0.027841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Doubt: P=0.054472 R=0.018699 F1=0.027841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,475 - INFO - Exaggeration,Minimisation: P=0.068641 R=0.011016 F1=0.018986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Exaggeration,Minimisation: P=0.068641 R=0.011016 F1=0.018986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,476 - INFO - Flag-Waving: P=0.170811 R=0.165787 F1=0.168261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Flag-Waving: P=0.170811 R=0.165787 F1=0.168261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,478 - INFO - Loaded_Language: P=0.300121 R=0.106622 F1=0.157345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Loaded_Language: P=0.300121 R=0.106622 F1=0.157345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,479 - INFO - Name_Calling,Labeling: P=0.197065 R=0.072940 F1=0.106471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Name_Calling,Labeling: P=0.197065 R=0.072940 F1=0.106471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,480 - INFO - Obfuscation,Intentional_Vagueness,Confusion: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Obfuscation,Intentional_Vagueness,Confusion: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,482 - INFO - Red_Herring: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Red_Herring: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,483 - INFO - Reductio_ad_hitlerum: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Reductio_ad_hitlerum: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,485 - INFO - Repetition: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Repetition: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,486 - INFO - Slogans: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Slogans: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,488 - INFO - Straw_Men: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Straw_Men: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,489 - INFO - Thought-terminating_Cliches: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Thought-terminating_Cliches: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 08:59:39,491 - INFO - Whataboutism: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Whataboutism: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08856340021423827\n",
      "Validation loss decreased (-0.025948 --> -0.088563).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  40%|████      | 2/5 [17:33<26:24, 528.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8529665711e4f71b5ce614e89b91692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=870, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc930383b0a14edea17f544fee810625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=128, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Counter check:  8\n",
      "{'submission': 'exp/all_class/spacy_viz/temp_pred.csv', 'gold': 'datasets-v5/tasks-2-3/test', 'debug_on_std': False, 'techniques_file': 'tools/data/propaganda-techniques-names.txt', 'log_file': 'exp/all_class/spacy_viz/temp_score.csv', 'fragments_only': False}\n",
      "2019-06-19 09:08:21,989 - INFO - Logging execution to file exp/all_class/spacy_viz/temp_score.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Logging execution to file exp/all_class/spacy_viz/temp_score.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:21,993 - INFO - Checking user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold folder datasets-v5/tasks-2-3/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Checking user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold folder datasets-v5/tasks-2-3/test\n",
      "DEBUG:propaganda_scorer:OK: all article ids have a correspondence in the list of articles from the reference dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,008 - INFO - Scoring user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold file datasets-v5/tasks-2-3/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Scoring user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold file datasets-v5/tasks-2-3/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,025 - INFO - Precision=88.102087/444=0.198428\tRecall=88.102087/927=0.095040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Precision=88.102087/444=0.198428\tRecall=88.102087/927=0.095040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,027 - INFO - F1=0.128522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:F1=0.128522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,028 - INFO - Appeal_to_Authority: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Appeal_to_Authority: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,030 - INFO - Appeal_to_fear-prejudice: P=0.029601 R=0.040416 F1=0.034173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Appeal_to_fear-prejudice: P=0.029601 R=0.040416 F1=0.034173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,032 - INFO - Bandwagon: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Bandwagon: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,033 - INFO - Black-and-White_Fallacy: P=0.398496 R=0.166040 F1=0.234410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Black-and-White_Fallacy: P=0.398496 R=0.166040 F1=0.234410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,035 - INFO - Causal_Oversimplification: P=0.112228 R=0.057924 F1=0.076411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Causal_Oversimplification: P=0.112228 R=0.057924 F1=0.076411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,036 - INFO - Doubt: P=0.050000 R=0.014925 F1=0.022989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Doubt: P=0.050000 R=0.014925 F1=0.022989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,038 - INFO - Exaggeration,Minimisation: P=0.166816 R=0.026773 F1=0.046141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Exaggeration,Minimisation: P=0.166816 R=0.026773 F1=0.046141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,039 - INFO - Flag-Waving: P=0.188353 R=0.182813 F1=0.185542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Flag-Waving: P=0.188353 R=0.182813 F1=0.185542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,041 - INFO - Loaded_Language: P=0.285243 R=0.149189 F1=0.195912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Loaded_Language: P=0.285243 R=0.149189 F1=0.195912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,043 - INFO - Name_Calling,Labeling: P=0.275655 R=0.159307 F1=0.201920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Name_Calling,Labeling: P=0.275655 R=0.159307 F1=0.201920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,044 - INFO - Obfuscation,Intentional_Vagueness,Confusion: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Obfuscation,Intentional_Vagueness,Confusion: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,045 - INFO - Red_Herring: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Red_Herring: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,047 - INFO - Reductio_ad_hitlerum: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Reductio_ad_hitlerum: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,048 - INFO - Repetition: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Repetition: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,050 - INFO - Slogans: P=0.420168 R=0.183824 F1=0.255754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Slogans: P=0.420168 R=0.183824 F1=0.255754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,051 - INFO - Straw_Men: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Straw_Men: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,052 - INFO - Thought-terminating_Cliches: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Thought-terminating_Cliches: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:08:22,054 - INFO - Whataboutism: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Whataboutism: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12852237319345247\n",
      "Validation loss decreased (-0.088563 --> -0.128522).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  60%|██████    | 3/5 [26:26<17:39, 529.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfce7e6d777e48498c04f8863b561314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=870, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240f97bed780489eb8533fbb7bd9e3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=128, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "Counter check:  21\n",
      "{'submission': 'exp/all_class/spacy_viz/temp_pred.csv', 'gold': 'datasets-v5/tasks-2-3/test', 'debug_on_std': False, 'techniques_file': 'tools/data/propaganda-techniques-names.txt', 'log_file': 'exp/all_class/spacy_viz/temp_score.csv', 'fragments_only': False}\n",
      "2019-06-19 09:17:16,337 - INFO - Logging execution to file exp/all_class/spacy_viz/temp_score.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Logging execution to file exp/all_class/spacy_viz/temp_score.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,342 - INFO - Checking user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold folder datasets-v5/tasks-2-3/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Checking user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold folder datasets-v5/tasks-2-3/test\n",
      "DEBUG:propaganda_scorer:OK: all article ids have a correspondence in the list of articles from the reference dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,358 - INFO - Scoring user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold file datasets-v5/tasks-2-3/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Scoring user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold file datasets-v5/tasks-2-3/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,380 - INFO - Precision=107.799404/640=0.168437\tRecall=107.799404/927=0.116288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Precision=107.799404/640=0.168437\tRecall=107.799404/927=0.116288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,381 - INFO - F1=0.137587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:F1=0.137587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,383 - INFO - Appeal_to_Authority: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Appeal_to_Authority: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,384 - INFO - Appeal_to_fear-prejudice: P=0.032392 R=0.040490 F1=0.035991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Appeal_to_fear-prejudice: P=0.032392 R=0.040490 F1=0.035991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,385 - INFO - Bandwagon: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Bandwagon: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,387 - INFO - Black-and-White_Fallacy: P=0.077595 R=0.168123 F1=0.106183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Black-and-White_Fallacy: P=0.077595 R=0.168123 F1=0.106183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,388 - INFO - Causal_Oversimplification: P=0.057814 R=0.063408 F1=0.060482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Causal_Oversimplification: P=0.057814 R=0.063408 F1=0.060482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,390 - INFO - Doubt: P=0.047133 R=0.036581 F1=0.041192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Doubt: P=0.047133 R=0.036581 F1=0.041192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,391 - INFO - Exaggeration,Minimisation: P=0.069606 R=0.021483 F1=0.032833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Exaggeration,Minimisation: P=0.069606 R=0.021483 F1=0.032833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,393 - INFO - Flag-Waving: P=0.110601 R=0.162649 F1=0.131668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Flag-Waving: P=0.110601 R=0.162649 F1=0.131668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,394 - INFO - Loaded_Language: P=0.293046 R=0.184118 F1=0.226149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Loaded_Language: P=0.293046 R=0.184118 F1=0.226149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,396 - INFO - Name_Calling,Labeling: P=0.234477 R=0.213160 F1=0.223311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Name_Calling,Labeling: P=0.234477 R=0.213160 F1=0.223311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,398 - INFO - Obfuscation,Intentional_Vagueness,Confusion: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Obfuscation,Intentional_Vagueness,Confusion: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,399 - INFO - Red_Herring: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Red_Herring: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,401 - INFO - Reductio_ad_hitlerum: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Reductio_ad_hitlerum: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,402 - INFO - Repetition: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Repetition: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,404 - INFO - Slogans: P=0.398897 R=0.199449 F1=0.265931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Slogans: P=0.398897 R=0.199449 F1=0.265931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,405 - INFO - Straw_Men: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Straw_Men: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,407 - INFO - Thought-terminating_Cliches: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Thought-terminating_Cliches: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:17:16,409 - INFO - Whataboutism: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Whataboutism: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13758698642163678\n",
      "Validation loss decreased (-0.128522 --> -0.137587).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  80%|████████  | 4/5 [35:10<08:47, 527.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c43fbaad914af6a2cf6f32d48af477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=870, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616f1caca13a4f34864662bec9a53a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluating', max=128, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "Counter check:  21\n",
      "{'submission': 'exp/all_class/spacy_viz/temp_pred.csv', 'gold': 'datasets-v5/tasks-2-3/test', 'debug_on_std': False, 'techniques_file': 'tools/data/propaganda-techniques-names.txt', 'log_file': 'exp/all_class/spacy_viz/temp_score.csv', 'fragments_only': False}\n",
      "2019-06-19 09:25:59,899 - INFO - Logging execution to file exp/all_class/spacy_viz/temp_score.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Logging execution to file exp/all_class/spacy_viz/temp_score.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,905 - INFO - Checking user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold folder datasets-v5/tasks-2-3/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Checking user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold folder datasets-v5/tasks-2-3/test\n",
      "DEBUG:propaganda_scorer:OK: all article ids have a correspondence in the list of articles from the reference dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,920 - INFO - Scoring user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold file datasets-v5/tasks-2-3/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Scoring user submitted file exp/all_class/spacy_viz/temp_pred.csv against gold file datasets-v5/tasks-2-3/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,946 - INFO - Precision=121.558127/752=0.161646\tRecall=121.558127/927=0.131131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Precision=121.558127/752=0.161646\tRecall=121.558127/927=0.131131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,947 - INFO - F1=0.144798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:F1=0.144798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,949 - INFO - Appeal_to_Authority: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Appeal_to_Authority: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,951 - INFO - Appeal_to_fear-prejudice: P=0.028734 R=0.039786 F1=0.033369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Appeal_to_fear-prejudice: P=0.028734 R=0.039786 F1=0.033369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,953 - INFO - Bandwagon: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Bandwagon: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,955 - INFO - Black-and-White_Fallacy: P=0.065763 R=0.197290 F1=0.098645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Black-and-White_Fallacy: P=0.065763 R=0.197290 F1=0.098645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,957 - INFO - Causal_Oversimplification: P=0.070257 R=0.072523 F1=0.071372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Causal_Oversimplification: P=0.070257 R=0.072523 F1=0.071372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,958 - INFO - Doubt: P=0.062681 R=0.069230 F1=0.065793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Doubt: P=0.062681 R=0.069230 F1=0.065793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,960 - INFO - Exaggeration,Minimisation: P=0.115749 R=0.057160 F1=0.076528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Exaggeration,Minimisation: P=0.115749 R=0.057160 F1=0.076528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,962 - INFO - Flag-Waving: P=0.084480 R=0.124235 F1=0.100571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Flag-Waving: P=0.084480 R=0.124235 F1=0.100571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,963 - INFO - Loaded_Language: P=0.275456 R=0.212029 F1=0.239616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Loaded_Language: P=0.275456 R=0.212029 F1=0.239616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,965 - INFO - Name_Calling,Labeling: P=0.239982 R=0.219724 F1=0.229406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Name_Calling,Labeling: P=0.239982 R=0.219724 F1=0.229406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,967 - INFO - Obfuscation,Intentional_Vagueness,Confusion: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Obfuscation,Intentional_Vagueness,Confusion: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,968 - INFO - Red_Herring: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Red_Herring: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,970 - INFO - Reductio_ad_hitlerum: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Reductio_ad_hitlerum: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,971 - INFO - Repetition: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Repetition: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,973 - INFO - Slogans: P=0.220501 R=0.192938 F1=0.205801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Slogans: P=0.220501 R=0.192938 F1=0.205801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,975 - INFO - Straw_Men: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Straw_Men: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,976 - INFO - Thought-terminating_Cliches: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Thought-terminating_Cliches: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-19 09:25:59,978 - INFO - Whataboutism: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:propaganda_scorer:Whataboutism: P=0.000000 R=0.000000 F1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1447982455156738\n",
      "Validation loss decreased (-0.137587 --> -0.144798).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch: 100%|██████████| 5/5 [44:04<00:00, 529.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'draw_curves' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-af35ce95b6d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Finished. Learning curves saved.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m     \u001b[0mdraw_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_scores_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask2_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m     \u001b[0;31m#df = pd.DataFrame({'col':trainlosses})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;31m#df.to_csv(\"trainlosses.csv\", sep='\\t', index=False, header=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'draw_curves' is not defined"
     ]
    }
   ],
   "source": [
    "#os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3,4'\n",
    "prop_tech_e, prop_tech, hash_token, end_token, p2id = settings(opt[\"techniques\"], opt[\"binaryLabel\"], opt[\"bio\"])\n",
    "logging.info(\"Training for class %s\" % (opt[\"binaryLabel\"]))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count(); \n",
    "logging.info(\"GPUs Detected: %s\" % (n_gpu))\n",
    "scorred_labels = list(range(1,(opt[\"nLabels\"]-2)))\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(opt[\"model\"], do_lower_case=opt[\"lowerCase\"]);\n",
    "print (hash_token, end_token)\n",
    "# Load Tokenized train and validation datasets\n",
    "tr_inputs, tr_tags, tr_masks, _ = make_set(p2id, opt[\"trainDataset\"], tokenizer, opt[\"binaryLabel\"], hash_token, end_token)\n",
    "val_inputs, val_tags, val_masks, cleaned, flat_list_i, flat_list, flat_list_s,_ = make_val_set(p2id, opt[\"evalDataset\"],\n",
    "                                                                                         tokenizer, opt[\"binaryLabel\"], hash_token, end_token)\n",
    "printable = tr_tags\n",
    "# ids, texts, _ = read_data(opt[\"testDataset\"], isLabels = False)\n",
    "# flat_list_i, flat_list, flat_list_s = test2list(ids, texts)\n",
    "truth_task2 = get_task2(val_tags)\n",
    "\n",
    "logging.info(\"Dataset loaded\")\n",
    "logging.info(\"Labels detected in train dataset: %s\" % (np.unique(tr_tags)))\n",
    "logging.info(\"Labels detected in val dataset: %s\" % (np.unique(val_tags)))\n",
    "\n",
    "# Balanced Sampling\n",
    "total_tags = np.zeros((opt[\"nLabels\"],))\n",
    "for x in tr_tags:\n",
    "     total_tags = total_tags+np.bincount(x)\n",
    "\n",
    "probs = 1./total_tags\n",
    "train_tokenweights = probs[tr_tags]\n",
    "weightage = np.sum(train_tokenweights, axis=1)\n",
    "   # Alternate method for weighting\n",
    "ws = np.ones((opt[\"nLabels\"],))\n",
    "ws[0] = 0\n",
    "\n",
    "ws[hash_token] = 0\n",
    "ws[end_token] = 0\n",
    "ws = ws+0.3\n",
    "prob = [max(x) for x in ws[tr_tags]]\n",
    "weightage = [x + y for x, y in zip(prob, (len(prob)*[0.1]))]    \n",
    "\n",
    "# Convert to pyTorch tensors\n",
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)\n",
    "\n",
    "# Create Dataloaders\n",
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "#train_sampler = WeightedRandomSampler(weights=weightage, num_samples=len(tr_tags),replacement=True)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=opt[\"trainBatch\"])\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=opt[\"trainBatch\"])\n",
    "\n",
    "# Model Initialize\n",
    "model = BertForTokenClassification.from_pretrained(opt[\"model\"], num_labels=opt[\"nLabels\"]);\n",
    "\n",
    "loss_scale = 0\n",
    "warmup_proportion = 0.1\n",
    "num_train_optimization_steps = int(len(train_data) / opt[\"trainBatch\"] ) * opt[\"nEpochs\"]\n",
    "\n",
    "# Prepare optimizer\n",
    "param_optimizer = list(model.named_parameters())\n",
    "\n",
    "# hack to remove pooler, which is not usedpython train.py --expID test --trainDataset dataset_train.csv --evalDataset dataset_dev.csv --model bert-base-cased --LR 3e-5 --trainBatch 12 --nEpochs 1\n",
    "# thus it produce None grad that break apex\n",
    "param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "# t_total matters\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=opt[\"LR\"],\n",
    "                     warmup=warmup_proportion,\n",
    "                     t_total=num_train_optimization_steps) \n",
    "\n",
    "model.to(device)\n",
    "\n",
    "if n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    logging.info(\"Training beginning on: %s\" % n_gpu)\n",
    "\n",
    "if opt[\"loadModel\"]:\n",
    "    print('Loading Model from {}'.format(opt[\"loadModel\"]))\n",
    "    model.load_state_dict(torch.load(opt[\"loadModel\"]))\n",
    "    if not os.path.exists(\"./exp/{}/{}\".format(opt[\"classType\"], opt[\"expID\"])):\n",
    "        try:\n",
    "            os.mkdir(\"./exp/{}/{}\".format(opt[\"classType\"], opt[\"expID\"]))\n",
    "        except FileNotFoundError:\n",
    "            os.mkdir(\"./exp/{}\".format(opt[\"classType\"]))\n",
    "            os.mkdir(\"./exp/{}/{}\".format(opt[\"classType\"], opt[\"expID\"]))\n",
    "else:\n",
    "    print('Create new model')\n",
    "    if not os.path.exists(\"./exp/{}/{}\".format(opt[\"classType\"], opt[\"expID\"])):\n",
    "        try:\n",
    "            os.mkdir(\"./exp/{}/{}\".format(opt[\"classType\"], opt[\"expID\"]))\n",
    "        except FileNotFoundError:\n",
    "            os.mkdir(\"./exp/{}\".format(opt[\"classType\"]))\n",
    "            os.mkdir(\"./exp/{}/{}\".format(opt[\"classType\"], opt[\"expID\"]))\n",
    "\n",
    "# F1 score shouldn't consider no-propaganda\n",
    "# and other auxiliary labels\n",
    "\n",
    "global_step = 0\n",
    "nb_tr_steps = 0\n",
    "tr_loss = 0\n",
    "max_grad_norm = 1.0\n",
    "best = 0\n",
    "early_stopping = EarlyStopping(patience=opt[\"patience\"], verbose=True)\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "f1_scores = []\n",
    "f1_scores_word = []\n",
    "task2_scores = []\n",
    "for i in trange(opt[\"nEpochs\"], desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    # Start only if train flag was passed\n",
    "    if (opt[\"train\"]):\n",
    "        model.train()\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "            if n_gpu == 1:\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "            # forward pass\n",
    "            loss = model(b_input_ids, token_type_ids=None,\n",
    "                        attention_mask=b_input_mask, labels=b_labels)\n",
    "            if n_gpu > 1:\n",
    "                loss = loss.mean()\n",
    "\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            nb_tr_examples += b_input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "        logging.info(f'EPOCH {i} done: Train Loss {(tr_loss/nb_tr_steps)}')\n",
    "        train_losses.append(tr_loss/nb_tr_steps)\n",
    "\n",
    "    # Evaluation on validation set or test set\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in tqdm(valid_dataloader, desc=\"Evaluating\"):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "                                attention_mask=b_input_mask, labels=b_labels)\n",
    "            logits = model(b_input_ids, token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.append(label_ids)\n",
    "\n",
    "        #tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        #eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    pred_task2 = get_task2(predictions)\n",
    "    logging.info(\"Precision, Recall, F1-Score, Support Task2: {}\".format(f1(pred_task2, truth_task2, average=None)))\n",
    "    f1_macro = f1_score(pred_task2, truth_task2, labels=scorred_labels, average=\"macro\")\n",
    "    task2_scores.append(f1_macro)\n",
    "    pickle.dump(printable, open( \"output_.p\", \"wb\"))\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "    logging.info(\"Validation loss: %s\" % (eval_loss))    \n",
    "    logging.info(\"Precision, Recall, F1-Score, Support: {}\".format(f1(list(itertools.chain(*predictions)), list(itertools.chain(*val_tags)), average=None)))\n",
    "    f1_macro = f1_score(list(itertools.chain(*predictions)), list(itertools.chain(*val_tags)), labels=scorred_labels, average=\"macro\")\n",
    "    logging.info(\"F1 Macro Dev Set: %s\" % f1_macro)\n",
    "    logging.info(\"Learning Rate: %s\" % (optimizer.get_lr()[0]))\n",
    "    valid_losses.append(eval_loss)\n",
    "    f1_scores_word.append(f1_macro)\n",
    "\n",
    "    df = get_char_level(flat_list_i, flat_list_s, predictions, cleaned, hash_token, end_token, prop_tech)\n",
    "    postfix = opt[\"testDataset\"].rsplit('/', 2)[-2]\n",
    "    if opt[\"loadModel\"]:\n",
    "        out_dir = opt[\"loadModel\"].rsplit('/', 1)[0] + \"/pred.\" + postfix\n",
    "    else:\n",
    "        out_dir = (\"exp/{}/{}/temp_pred.csv\".format(opt[\"classType\"], opt[\"expID\"]))\n",
    "    df.to_csv(out_dir, sep='\\t', index=False, header=False) \n",
    "    logging.info(\"Predictions written to: %s\" % (out_dir))\n",
    "\n",
    "    if opt[\"loadModel\"]:\n",
    "        out_file = opt[\"loadModel\"].rsplit('/', 1)[0] + \"/score.\" + postfix\n",
    "    else:\n",
    "        out_file = (\"exp/{}/{}/temp_score.csv\".format(opt[\"classType\"], opt[\"expID\"]))\n",
    "\n",
    "    if opt[\"classType\"] != \"binary\":\n",
    "        char_predict = tools.task3_scorer_onefile.main([\"-s\", out_dir, \"-r\", opt[\"testDataset\"], \"-t\", opt[\"techniques\"], \"-l\", out_file])\n",
    "    else:\n",
    "        char_predict = tools.task3_scorer_onefile.main([\"-s\", out_dir, \"-r\", opt[\"testDataset\"], \"-t\", opt[\"techniques\"], \"-f\", \"-l\", out_file])\n",
    "    f1_scores.append(char_predict) \n",
    "    print (char_predict)\n",
    "\n",
    "    # early_stopping needs the validation loss to check if it has decresed, \n",
    "    # and if it has, it will make a checkpoint of the current model\n",
    "    if not opt[\"train\"]:\n",
    "        break\n",
    "    early_stopping(char_predict*(-1), model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        logging.info(\"Early stopping\")\n",
    "        break\n",
    "    # Save checkpoints\n",
    "    if i % opt[\"snapshot\"] == 0:\n",
    "        if not os.path.exists(\"./exp/{}/{}/{}\".format(opt[\"classType\"], opt[\"expID\"], i)):\n",
    "            try:\n",
    "                os.mkdir(\"./exp/{}/{}/{}\".format(opt[\"classType\"], opt[\"expID\"], i))\n",
    "            except FileNotFoundError:\n",
    "                os.mkdir(\"./exp/{}/{}/{}\".format(opt[\"classType\"], opt[\"expID\"], i))\n",
    "        torch.save(\n",
    "            model.state_dict(), './exp/{}/{}/{}/model_{}.pth'.format(opt[\"classType\"], opt[\"expID\"], i, i))\n",
    "        torch.save(\n",
    "            opt, './exp/{}/{}/{}/option.pth'.format(opt[\"classType\"], opt[\"expID\"], i))\n",
    "        torch.save(\n",
    "            optimizer, './exp/{}/{}/{}/optimizer.pth'.format(opt[\"classType\"], opt[\"expID\"], i))\n",
    "\n",
    "\n",
    "    # Save model based on best F1 score and if epoch is greater than 3\n",
    "    '''if f1_macro > best and i > 3:\n",
    "    # Save a trained model and the associated configuration\n",
    "        torch.save(\n",
    "            model.state_dict(), './exp/{}/{}/best_model.pth'.format(opt[\"classType\"], opt[\"expID\"]))\n",
    "        torch.save(\n",
    "            opt, './exp/{}/{}/option.pth'.format(opt[\"classType\"], opt[\"expID\"]))\n",
    "        torch.save(\n",
    "            optimizer, './exp/{}/{}/optimizer.pth'.format(opt[\"classType\"], opt[\"expID\"]))\n",
    "        #model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "        #output_model_file = os.path.join(\"./exp/{}/{}\".format(opt[\"classType\"], opt[\"expID\"]), \"best_model.pth\")\n",
    "        #torch.save(model_to_save.state_dict(), output_model_file)\n",
    "        best = f1_macro\n",
    "        logging.info(\"New best model\")\n",
    "    '''\n",
    "if opt[\"train\"]:\n",
    "    logging.info(\"Training Finished. Learning curves saved.\")\n",
    "    draw_curves(train_losses, valid_losses, f1_scores, f1_scores_word, task2_scores)\n",
    "    #df = pd.DataFrame({'col':trainlosses})\n",
    "    #df.to_csv(\"trainlosses.csv\", sep='\\t', index=False, header=False) \n",
    "    #df = pd.DataFrame({'col':validlosses})\n",
    "    #df.to_csv(\"validlosses.csv\", sep='\\t', index=False, header=False) \n",
    "    #df = pd.DataFrame({'col':f1scores})\n",
    "    #df.to_csv(\"f1scores.csv\", sep='\\t', index=False, header=False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3,4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForTokenClassification:\n\tMissing key(s) in state_dict: \"bert.embeddings.word_embeddings.weight\", \"bert.embeddings.position_embeddings.weight\", \"bert.embeddings.token_type_embeddings.weight\", \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.LayerNorm.bias\", \"bert.encoder.layer.0.attention.self.query.weight\", \"bert.encoder.layer.0.attention.self.query.bias\", \"bert.encoder.layer.0.attention.self.key.weight\", \"bert.encoder.layer.0.attention.self.key.bias\", \"bert.encoder.layer.0.attention.self.value.weight\", \"bert.encoder.layer.0.attention.self.value.bias\", \"bert.encoder.layer.0.attention.output.dense.weight\", \"bert.encoder.layer.0.attention.output.dense.bias\", \"bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.encoder.layer.0.intermediate.dense.weight\", \"bert.encoder.layer.0.intermediate.dense.bias\", \"bert.encoder.layer.0.output.dense.weight\", \"bert.encoder.layer.0.output.dense.bias\", \"bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.encoder.layer.1.attention.self.query.weight\", \"bert.encoder.layer.1.attention.self.query.bias\", \"bert.encoder.layer.1.attention.self.key.weight\", \"bert.encoder.layer.1.attention.self.key.bias\", \"bert.encoder.layer.1.attention.self.value.weight\", \"bert.encoder.layer.1.attention.self.value.bias\", \"bert.encoder.layer.1.attention.output.dense.weight\", \"bert.encoder.layer.1.attention.output.dense.bias\", \"bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.encoder.layer.1.intermediate.dense.weight\", \"bert.encoder.layer.1.intermediate.dense.bias\", \"bert.encoder.layer.1.output.dense.weight\", \"bert.encoder.layer.1.output.dense.bias\", \"bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.encoder.layer.2.attention.self.query.weight\", \"bert.encoder.layer.2.attention.self.query.bias\", \"bert.encoder.layer.2.attention.self.key.weight\", \"bert.encoder.layer.2.attention.self.key.bias\", \"bert.encoder.layer.2.attention.self.value.weight\", \"bert.encoder.layer.2.attention.self.value.bias\", \"bert.encoder.layer.2.attention.output.dense.weight\", \"bert.encoder.layer.2.attention.output.dense.bias\", \"bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.encoder.layer.2.intermediate.dense.weight\", \"bert.encoder.layer.2.intermediate.dense.bias\", \"bert.encoder.layer.2.output.dense.weight\", \"bert.encoder.layer.2.output.dense.bias\", \"bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.encoder.layer.3.attention.self.query.weight\", \"bert.encoder.layer.3.attention.self.query.bias\", \"bert.encoder.layer.3.attention.self.key.weight\", \"bert.encoder.layer.3.attention.self.key.bias\", \"bert.encoder.layer.3.attention.self.value.weight\", \"bert.encoder.layer.3.attention.self.value.bias\", \"bert.encoder.layer.3.attention.output.dense.weight\", \"bert.encoder.layer.3.attention.output.dense.bias\", \"bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.encoder.layer.3.intermediate.dense.weight\", \"bert.encoder.layer.3.intermediate.dense.bias\", \"bert.encoder.layer.3.output.dense.weight\", \"bert.encoder.layer.3.output.dense.bias\", \"bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.encoder.layer.4.attention.self.query.weight\", \"bert.encoder.layer.4.attention.self.query.bias\", \"bert.encoder.layer.4.attention.self.key.weight\", \"bert.encoder.layer.4.attention.self.key.bias\", \"bert.encoder.layer.4.attention.self.value.weight\", \"bert.encoder.layer.4.attention.self.value.bias\", \"bert.encoder.layer.4.attention.output.dense.weight\", \"bert.encoder.layer.4.attention.output.dense.bias\", \"bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.encoder.layer.4.intermediate.dense.weight\", \"bert.encoder.layer.4.intermediate.dense.bias\", \"bert.encoder.layer.4.output.dense.weight\", \"bert.encoder.layer.4.output.dense.bias\", \"bert.encoder.layer.4.output.LayerNorm.weight\", \"bert.encoder.layer.4.output.LayerNorm.bias\", \"bert.encoder.layer.5.attention.self.query.weight\", \"bert.encoder.layer.5.attention.self.query.bias\", \"bert.encoder.layer.5.attention.self.key.weight\", \"bert.encoder.layer.5.attention.self.key.bias\", \"bert.encoder.layer.5.attention.self.value.weight\", \"bert.encoder.layer.5.attention.self.value.bias\", \"bert.encoder.layer.5.attention.output.dense.weight\", \"bert.encoder.layer.5.attention.output.dense.bias\", \"bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.encoder.layer.5.intermediate.dense.weight\", \"bert.encoder.layer.5.intermediate.dense.bias\", \"bert.encoder.layer.5.output.dense.weight\", \"bert.encoder.layer.5.output.dense.bias\", \"bert.encoder.layer.5.output.LayerNorm.weight\", \"bert.encoder.layer.5.output.LayerNorm.bias\", \"bert.encoder.layer.6.attention.self.query.weight\", \"bert.encoder.layer.6.attention.self.query.bias\", \"bert.encoder.layer.6.attention.self.key.weight\", \"bert.encoder.layer.6.attention.self.key.bias\", \"bert.encoder.layer.6.attention.self.value.weight\", \"bert.encoder.layer.6.attention.self.value.bias\", \"bert.encoder.layer.6.attention.output.dense.weight\", \"bert.encoder.layer.6.attention.output.dense.bias\", \"bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.encoder.layer.6.intermediate.dense.weight\", \"bert.encoder.layer.6.intermediate.dense.bias\", \"bert.encoder.layer.6.output.dense.weight\", \"bert.encoder.layer.6.output.dense.bias\", \"bert.encoder.layer.6.output.LayerNorm.weight\", \"bert.encoder.layer.6.output.LayerNorm.bias\", \"bert.encoder.layer.7.attention.self.query.weight\", \"bert.encoder.layer.7.attention.self.query.bias\", \"bert.encoder.layer.7.attention.self.key.weight\", \"bert.encoder.layer.7.attention.self.key.bias\", \"bert.encoder.layer.7.attention.self.value.weight\", \"bert.encoder.layer.7.attention.self.value.bias\", \"bert.encoder.layer.7.attention.output.dense.weight\", \"bert.encoder.layer.7.attention.output.dense.bias\", \"bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.encoder.layer.7.intermediate.dense.weight\", \"bert.encoder.layer.7.intermediate.dense.bias\", \"bert.encoder.layer.7.output.dense.weight\", \"bert.encoder.layer.7.output.dense.bias\", \"bert.encoder.layer.7.output.LayerNorm.weight\", \"bert.encoder.layer.7.output.LayerNorm.bias\", \"bert.encoder.layer.8.attention.self.query.weight\", \"bert.encoder.layer.8.attention.self.query.bias\", \"bert.encoder.layer.8.attention.self.key.weight\", \"bert.encoder.layer.8.attention.self.key.bias\", \"bert.encoder.layer.8.attention.self.value.weight\", \"bert.encoder.layer.8.attention.self.value.bias\", \"bert.encoder.layer.8.attention.output.dense.weight\", \"bert.encoder.layer.8.attention.output.dense.bias\", \"bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.encoder.layer.8.intermediate.dense.weight\", \"bert.encoder.layer.8.intermediate.dense.bias\", \"bert.encoder.layer.8.output.dense.weight\", \"bert.encoder.layer.8.output.dense.bias\", \"bert.encoder.layer.8.output.LayerNorm.weight\", \"bert.encoder.layer.8.output.LayerNorm.bias\", \"bert.encoder.layer.9.attention.self.query.weight\", \"bert.encoder.layer.9.attention.self.query.bias\", \"bert.encoder.layer.9.attention.self.key.weight\", \"bert.encoder.layer.9.attention.self.key.bias\", \"bert.encoder.layer.9.attention.self.value.weight\", \"bert.encoder.layer.9.attention.self.value.bias\", \"bert.encoder.layer.9.attention.output.dense.weight\", \"bert.encoder.layer.9.attention.output.dense.bias\", \"bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.encoder.layer.9.intermediate.dense.weight\", \"bert.encoder.layer.9.intermediate.dense.bias\", \"bert.encoder.layer.9.output.dense.weight\", \"bert.encoder.layer.9.output.dense.bias\", \"bert.encoder.layer.9.output.LayerNorm.weight\", \"bert.encoder.layer.9.output.LayerNorm.bias\", \"bert.encoder.layer.10.attention.self.query.weight\", \"bert.encoder.layer.10.attention.self.query.bias\", \"bert.encoder.layer.10.attention.self.key.weight\", \"bert.encoder.layer.10.attention.self.key.bias\", \"bert.encoder.layer.10.attention.self.value.weight\", \"bert.encoder.layer.10.attention.self.value.bias\", \"bert.encoder.layer.10.attention.output.dense.weight\", \"bert.encoder.layer.10.attention.output.dense.bias\", \"bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.encoder.layer.10.intermediate.dense.weight\", \"bert.encoder.layer.10.intermediate.dense.bias\", \"bert.encoder.layer.10.output.dense.weight\", \"bert.encoder.layer.10.output.dense.bias\", \"bert.encoder.layer.10.output.LayerNorm.weight\", \"bert.encoder.layer.10.output.LayerNorm.bias\", \"bert.encoder.layer.11.attention.self.query.weight\", \"bert.encoder.layer.11.attention.self.query.bias\", \"bert.encoder.layer.11.attention.self.key.weight\", \"bert.encoder.layer.11.attention.self.key.bias\", \"bert.encoder.layer.11.attention.self.value.weight\", \"bert.encoder.layer.11.attention.self.value.bias\", \"bert.encoder.layer.11.attention.output.dense.weight\", \"bert.encoder.layer.11.attention.output.dense.bias\", \"bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.encoder.layer.11.intermediate.dense.weight\", \"bert.encoder.layer.11.intermediate.dense.bias\", \"bert.encoder.layer.11.output.dense.weight\", \"bert.encoder.layer.11.output.dense.bias\", \"bert.encoder.layer.11.output.LayerNorm.weight\", \"bert.encoder.layer.11.output.LayerNorm.bias\", \"bert.pooler.dense.weight\", \"bert.pooler.dense.bias\", \"classifier_1.weight\", \"classifier_1.bias\", \"classifier_2.weight\", \"classifier_2.bias\". \n\tUnexpected key(s) in state_dict: \"module.bert.embeddings.word_embeddings.weight\", \"module.bert.embeddings.position_embeddings.weight\", \"module.bert.embeddings.token_type_embeddings.weight\", \"module.bert.embeddings.LayerNorm.weight\", \"module.bert.embeddings.LayerNorm.bias\", \"module.bert.encoder.layer.0.attention.self.query.weight\", \"module.bert.encoder.layer.0.attention.self.query.bias\", \"module.bert.encoder.layer.0.attention.self.key.weight\", \"module.bert.encoder.layer.0.attention.self.key.bias\", \"module.bert.encoder.layer.0.attention.self.value.weight\", \"module.bert.encoder.layer.0.attention.self.value.bias\", \"module.bert.encoder.layer.0.attention.output.dense.weight\", \"module.bert.encoder.layer.0.attention.output.dense.bias\", \"module.bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.0.intermediate.dense.weight\", \"module.bert.encoder.layer.0.intermediate.dense.bias\", \"module.bert.encoder.layer.0.output.dense.weight\", \"module.bert.encoder.layer.0.output.dense.bias\", \"module.bert.encoder.layer.0.output.LayerNorm.weight\", \"module.bert.encoder.layer.0.output.LayerNorm.bias\", \"module.bert.encoder.layer.1.attention.self.query.weight\", \"module.bert.encoder.layer.1.attention.self.query.bias\", \"module.bert.encoder.layer.1.attention.self.key.weight\", \"module.bert.encoder.layer.1.attention.self.key.bias\", \"module.bert.encoder.layer.1.attention.self.value.weight\", \"module.bert.encoder.layer.1.attention.self.value.bias\", \"module.bert.encoder.layer.1.attention.output.dense.weight\", \"module.bert.encoder.layer.1.attention.output.dense.bias\", \"module.bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.1.intermediate.dense.weight\", \"module.bert.encoder.layer.1.intermediate.dense.bias\", \"module.bert.encoder.layer.1.output.dense.weight\", \"module.bert.encoder.layer.1.output.dense.bias\", \"module.bert.encoder.layer.1.output.LayerNorm.weight\", \"module.bert.encoder.layer.1.output.LayerNorm.bias\", \"module.bert.encoder.layer.2.attention.self.query.weight\", \"module.bert.encoder.layer.2.attention.self.query.bias\", \"module.bert.encoder.layer.2.attention.self.key.weight\", \"module.bert.encoder.layer.2.attention.self.key.bias\", \"module.bert.encoder.layer.2.attention.self.value.weight\", \"module.bert.encoder.layer.2.attention.self.value.bias\", \"module.bert.encoder.layer.2.attention.output.dense.weight\", \"module.bert.encoder.layer.2.attention.output.dense.bias\", \"module.bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.2.intermediate.dense.weight\", \"module.bert.encoder.layer.2.intermediate.dense.bias\", \"module.bert.encoder.layer.2.output.dense.weight\", \"module.bert.encoder.layer.2.output.dense.bias\", \"module.bert.encoder.layer.2.output.LayerNorm.weight\", \"module.bert.encoder.layer.2.output.LayerNorm.bias\", \"module.bert.encoder.layer.3.attention.self.query.weight\", \"module.bert.encoder.layer.3.attention.self.query.bias\", \"module.bert.encoder.layer.3.attention.self.key.weight\", \"module.bert.encoder.layer.3.attention.self.key.bias\", \"module.bert.encoder.layer.3.attention.self.value.weight\", \"module.bert.encoder.layer.3.attention.self.value.bias\", \"module.bert.encoder.layer.3.attention.output.dense.weight\", \"module.bert.encoder.layer.3.attention.output.dense.bias\", \"module.bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.3.intermediate.dense.weight\", \"module.bert.encoder.layer.3.intermediate.dense.bias\", \"module.bert.encoder.layer.3.output.dense.weight\", \"module.bert.encoder.layer.3.output.dense.bias\", \"module.bert.encoder.layer.3.output.LayerNorm.weight\", \"module.bert.encoder.layer.3.output.LayerNorm.bias\", \"module.bert.encoder.layer.4.attention.self.query.weight\", \"module.bert.encoder.layer.4.attention.self.query.bias\", \"module.bert.encoder.layer.4.attention.self.key.weight\", \"module.bert.encoder.layer.4.attention.self.key.bias\", \"module.bert.encoder.layer.4.attention.self.value.weight\", \"module.bert.encoder.layer.4.attention.self.value.bias\", \"module.bert.encoder.layer.4.attention.output.dense.weight\", \"module.bert.encoder.layer.4.attention.output.dense.bias\", \"module.bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.4.intermediate.dense.weight\", \"module.bert.encoder.layer.4.intermediate.dense.bias\", \"module.bert.encoder.layer.4.output.dense.weight\", \"module.bert.encoder.layer.4.output.dense.bias\", \"module.bert.encoder.layer.4.output.LayerNorm.weight\", \"module.bert.encoder.layer.4.output.LayerNorm.bias\", \"module.bert.encoder.layer.5.attention.self.query.weight\", \"module.bert.encoder.layer.5.attention.self.query.bias\", \"module.bert.encoder.layer.5.attention.self.key.weight\", \"module.bert.encoder.layer.5.attention.self.key.bias\", \"module.bert.encoder.layer.5.attention.self.value.weight\", \"module.bert.encoder.layer.5.attention.self.value.bias\", \"module.bert.encoder.layer.5.attention.output.dense.weight\", \"module.bert.encoder.layer.5.attention.output.dense.bias\", \"module.bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.5.intermediate.dense.weight\", \"module.bert.encoder.layer.5.intermediate.dense.bias\", \"module.bert.encoder.layer.5.output.dense.weight\", \"module.bert.encoder.layer.5.output.dense.bias\", \"module.bert.encoder.layer.5.output.LayerNorm.weight\", \"module.bert.encoder.layer.5.output.LayerNorm.bias\", \"module.bert.encoder.layer.6.attention.self.query.weight\", \"module.bert.encoder.layer.6.attention.self.query.bias\", \"module.bert.encoder.layer.6.attention.self.key.weight\", \"module.bert.encoder.layer.6.attention.self.key.bias\", \"module.bert.encoder.layer.6.attention.self.value.weight\", \"module.bert.encoder.layer.6.attention.self.value.bias\", \"module.bert.encoder.layer.6.attention.output.dense.weight\", \"module.bert.encoder.layer.6.attention.output.dense.bias\", \"module.bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.6.intermediate.dense.weight\", \"module.bert.encoder.layer.6.intermediate.dense.bias\", \"module.bert.encoder.layer.6.output.dense.weight\", \"module.bert.encoder.layer.6.output.dense.bias\", \"module.bert.encoder.layer.6.output.LayerNorm.weight\", \"module.bert.encoder.layer.6.output.LayerNorm.bias\", \"module.bert.encoder.layer.7.attention.self.query.weight\", \"module.bert.encoder.layer.7.attention.self.query.bias\", \"module.bert.encoder.layer.7.attention.self.key.weight\", \"module.bert.encoder.layer.7.attention.self.key.bias\", \"module.bert.encoder.layer.7.attention.self.value.weight\", \"module.bert.encoder.layer.7.attention.self.value.bias\", \"module.bert.encoder.layer.7.attention.output.dense.weight\", \"module.bert.encoder.layer.7.attention.output.dense.bias\", \"module.bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.7.intermediate.dense.weight\", \"module.bert.encoder.layer.7.intermediate.dense.bias\", \"module.bert.encoder.layer.7.output.dense.weight\", \"module.bert.encoder.layer.7.output.dense.bias\", \"module.bert.encoder.layer.7.output.LayerNorm.weight\", \"module.bert.encoder.layer.7.output.LayerNorm.bias\", \"module.bert.encoder.layer.8.attention.self.query.weight\", \"module.bert.encoder.layer.8.attention.self.query.bias\", \"module.bert.encoder.layer.8.attention.self.key.weight\", \"module.bert.encoder.layer.8.attention.self.key.bias\", \"module.bert.encoder.layer.8.attention.self.value.weight\", \"module.bert.encoder.layer.8.attention.self.value.bias\", \"module.bert.encoder.layer.8.attention.output.dense.weight\", \"module.bert.encoder.layer.8.attention.output.dense.bias\", \"module.bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.8.intermediate.dense.weight\", \"module.bert.encoder.layer.8.intermediate.dense.bias\", \"module.bert.encoder.layer.8.output.dense.weight\", \"module.bert.encoder.layer.8.output.dense.bias\", \"module.bert.encoder.layer.8.output.LayerNorm.weight\", \"module.bert.encoder.layer.8.output.LayerNorm.bias\", \"module.bert.encoder.layer.9.attention.self.query.weight\", \"module.bert.encoder.layer.9.attention.self.query.bias\", \"module.bert.encoder.layer.9.attention.self.key.weight\", \"module.bert.encoder.layer.9.attention.self.key.bias\", \"module.bert.encoder.layer.9.attention.self.value.weight\", \"module.bert.encoder.layer.9.attention.self.value.bias\", \"module.bert.encoder.layer.9.attention.output.dense.weight\", \"module.bert.encoder.layer.9.attention.output.dense.bias\", \"module.bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.9.intermediate.dense.weight\", \"module.bert.encoder.layer.9.intermediate.dense.bias\", \"module.bert.encoder.layer.9.output.dense.weight\", \"module.bert.encoder.layer.9.output.dense.bias\", \"module.bert.encoder.layer.9.output.LayerNorm.weight\", \"module.bert.encoder.layer.9.output.LayerNorm.bias\", \"module.bert.encoder.layer.10.attention.self.query.weight\", \"module.bert.encoder.layer.10.attention.self.query.bias\", \"module.bert.encoder.layer.10.attention.self.key.weight\", \"module.bert.encoder.layer.10.attention.self.key.bias\", \"module.bert.encoder.layer.10.attention.self.value.weight\", \"module.bert.encoder.layer.10.attention.self.value.bias\", \"module.bert.encoder.layer.10.attention.output.dense.weight\", \"module.bert.encoder.layer.10.attention.output.dense.bias\", \"module.bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.10.intermediate.dense.weight\", \"module.bert.encoder.layer.10.intermediate.dense.bias\", \"module.bert.encoder.layer.10.output.dense.weight\", \"module.bert.encoder.layer.10.output.dense.bias\", \"module.bert.encoder.layer.10.output.LayerNorm.weight\", \"module.bert.encoder.layer.10.output.LayerNorm.bias\", \"module.bert.encoder.layer.11.attention.self.query.weight\", \"module.bert.encoder.layer.11.attention.self.query.bias\", \"module.bert.encoder.layer.11.attention.self.key.weight\", \"module.bert.encoder.layer.11.attention.self.key.bias\", \"module.bert.encoder.layer.11.attention.self.value.weight\", \"module.bert.encoder.layer.11.attention.self.value.bias\", \"module.bert.encoder.layer.11.attention.output.dense.weight\", \"module.bert.encoder.layer.11.attention.output.dense.bias\", \"module.bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.11.intermediate.dense.weight\", \"module.bert.encoder.layer.11.intermediate.dense.bias\", \"module.bert.encoder.layer.11.output.dense.weight\", \"module.bert.encoder.layer.11.output.dense.bias\", \"module.bert.encoder.layer.11.output.LayerNorm.weight\", \"module.bert.encoder.layer.11.output.LayerNorm.bias\", \"module.bert.pooler.dense.weight\", \"module.bert.pooler.dense.bias\", \"module.classifier.weight\", \"module.classifier.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3e98247ceb23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loadModel\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 777\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForTokenClassification:\n\tMissing key(s) in state_dict: \"bert.embeddings.word_embeddings.weight\", \"bert.embeddings.position_embeddings.weight\", \"bert.embeddings.token_type_embeddings.weight\", \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.LayerNorm.bias\", \"bert.encoder.layer.0.attention.self.query.weight\", \"bert.encoder.layer.0.attention.self.query.bias\", \"bert.encoder.layer.0.attention.self.key.weight\", \"bert.encoder.layer.0.attention.self.key.bias\", \"bert.encoder.layer.0.attention.self.value.weight\", \"bert.encoder.layer.0.attention.self.value.bias\", \"bert.encoder.layer.0.attention.output.dense.weight\", \"bert.encoder.layer.0.attention.output.dense.bias\", \"bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"bert.encoder.layer.0.intermediate.dense.weight\", \"bert.encoder.layer.0.intermediate.dense.bias\", \"bert.encoder.layer.0.output.dense.weight\", \"bert.encoder.layer.0.output.dense.bias\", \"bert.encoder.layer.0.output.LayerNorm.weight\", \"bert.encoder.layer.0.output.LayerNorm.bias\", \"bert.encoder.layer.1.attention.self.query.weight\", \"bert.encoder.layer.1.attention.self.query.bias\", \"bert.encoder.layer.1.attention.self.key.weight\", \"bert.encoder.layer.1.attention.self.key.bias\", \"bert.encoder.layer.1.attention.self.value.weight\", \"bert.encoder.layer.1.attention.self.value.bias\", \"bert.encoder.layer.1.attention.output.dense.weight\", \"bert.encoder.layer.1.attention.output.dense.bias\", \"bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"bert.encoder.layer.1.intermediate.dense.weight\", \"bert.encoder.layer.1.intermediate.dense.bias\", \"bert.encoder.layer.1.output.dense.weight\", \"bert.encoder.layer.1.output.dense.bias\", \"bert.encoder.layer.1.output.LayerNorm.weight\", \"bert.encoder.layer.1.output.LayerNorm.bias\", \"bert.encoder.layer.2.attention.self.query.weight\", \"bert.encoder.layer.2.attention.self.query.bias\", \"bert.encoder.layer.2.attention.self.key.weight\", \"bert.encoder.layer.2.attention.self.key.bias\", \"bert.encoder.layer.2.attention.self.value.weight\", \"bert.encoder.layer.2.attention.self.value.bias\", \"bert.encoder.layer.2.attention.output.dense.weight\", \"bert.encoder.layer.2.attention.output.dense.bias\", \"bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"bert.encoder.layer.2.intermediate.dense.weight\", \"bert.encoder.layer.2.intermediate.dense.bias\", \"bert.encoder.layer.2.output.dense.weight\", \"bert.encoder.layer.2.output.dense.bias\", \"bert.encoder.layer.2.output.LayerNorm.weight\", \"bert.encoder.layer.2.output.LayerNorm.bias\", \"bert.encoder.layer.3.attention.self.query.weight\", \"bert.encoder.layer.3.attention.self.query.bias\", \"bert.encoder.layer.3.attention.self.key.weight\", \"bert.encoder.layer.3.attention.self.key.bias\", \"bert.encoder.layer.3.attention.self.value.weight\", \"bert.encoder.layer.3.attention.self.value.bias\", \"bert.encoder.layer.3.attention.output.dense.weight\", \"bert.encoder.layer.3.attention.output.dense.bias\", \"bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"bert.encoder.layer.3.intermediate.dense.weight\", \"bert.encoder.layer.3.intermediate.dense.bias\", \"bert.encoder.layer.3.output.dense.weight\", \"bert.encoder.layer.3.output.dense.bias\", \"bert.encoder.layer.3.output.LayerNorm.weight\", \"bert.encoder.layer.3.output.LayerNorm.bias\", \"bert.encoder.layer.4.attention.self.query.weight\", \"bert.encoder.layer.4.attention.self.query.bias\", \"bert.encoder.layer.4.attention.self.key.weight\", \"bert.encoder.layer.4.attention.self.key.bias\", \"bert.encoder.layer.4.attention.self.value.weight\", \"bert.encoder.layer.4.attention.self.value.bias\", \"bert.encoder.layer.4.attention.output.dense.weight\", \"bert.encoder.layer.4.attention.output.dense.bias\", \"bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"bert.encoder.layer.4.intermediate.dense.weight\", \"bert.encoder.layer.4.intermediate.dense.bias\", \"bert.encoder.layer.4.output.dense.weight\", \"bert.encoder.layer.4.output.dense.bias\", \"bert.encoder.layer.4.output.LayerNorm.weight\", \"bert.encoder.layer.4.output.LayerNorm.bias\", \"bert.encoder.layer.5.attention.self.query.weight\", \"bert.encoder.layer.5.attention.self.query.bias\", \"bert.encoder.layer.5.attention.self.key.weight\", \"bert.encoder.layer.5.attention.self.key.bias\", \"bert.encoder.layer.5.attention.self.value.weight\", \"bert.encoder.layer.5.attention.self.value.bias\", \"bert.encoder.layer.5.attention.output.dense.weight\", \"bert.encoder.layer.5.attention.output.dense.bias\", \"bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"bert.encoder.layer.5.intermediate.dense.weight\", \"bert.encoder.layer.5.intermediate.dense.bias\", \"bert.encoder.layer.5.output.dense.weight\", \"bert.encoder.layer.5.output.dense.bias\", \"bert.encoder.layer.5.output.LayerNorm.weight\", \"bert.encoder.layer.5.output.LayerNorm.bias\", \"bert.encoder.layer.6.attention.self.query.weight\", \"bert.encoder.layer.6.attention.self.query.bias\", \"bert.encoder.layer.6.attention.self.key.weight\", \"bert.encoder.layer.6.attention.self.key.bias\", \"bert.encoder.layer.6.attention.self.value.weight\", \"bert.encoder.layer.6.attention.self.value.bias\", \"bert.encoder.layer.6.attention.output.dense.weight\", \"bert.encoder.layer.6.attention.output.dense.bias\", \"bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"bert.encoder.layer.6.intermediate.dense.weight\", \"bert.encoder.layer.6.intermediate.dense.bias\", \"bert.encoder.layer.6.output.dense.weight\", \"bert.encoder.layer.6.output.dense.bias\", \"bert.encoder.layer.6.output.LayerNorm.weight\", \"bert.encoder.layer.6.output.LayerNorm.bias\", \"bert.encoder.layer.7.attention.self.query.weight\", \"bert.encoder.layer.7.attention.self.query.bias\", \"bert.encoder.layer.7.attention.self.key.weight\", \"bert.encoder.layer.7.attention.self.key.bias\", \"bert.encoder.layer.7.attention.self.value.weight\", \"bert.encoder.layer.7.attention.self.value.bias\", \"bert.encoder.layer.7.attention.output.dense.weight\", \"bert.encoder.layer.7.attention.output.dense.bias\", \"bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"bert.encoder.layer.7.intermediate.dense.weight\", \"bert.encoder.layer.7.intermediate.dense.bias\", \"bert.encoder.layer.7.output.dense.weight\", \"bert.encoder.layer.7.output.dense.bias\", \"bert.encoder.layer.7.output.LayerNorm.weight\", \"bert.encoder.layer.7.output.LayerNorm.bias\", \"bert.encoder.layer.8.attention.self.query.weight\", \"bert.encoder.layer.8.attention.self.query.bias\", \"bert.encoder.layer.8.attention.self.key.weight\", \"bert.encoder.layer.8.attention.self.key.bias\", \"bert.encoder.layer.8.attention.self.value.weight\", \"bert.encoder.layer.8.attention.self.value.bias\", \"bert.encoder.layer.8.attention.output.dense.weight\", \"bert.encoder.layer.8.attention.output.dense.bias\", \"bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"bert.encoder.layer.8.intermediate.dense.weight\", \"bert.encoder.layer.8.intermediate.dense.bias\", \"bert.encoder.layer.8.output.dense.weight\", \"bert.encoder.layer.8.output.dense.bias\", \"bert.encoder.layer.8.output.LayerNorm.weight\", \"bert.encoder.layer.8.output.LayerNorm.bias\", \"bert.encoder.layer.9.attention.self.query.weight\", \"bert.encoder.layer.9.attention.self.query.bias\", \"bert.encoder.layer.9.attention.self.key.weight\", \"bert.encoder.layer.9.attention.self.key.bias\", \"bert.encoder.layer.9.attention.self.value.weight\", \"bert.encoder.layer.9.attention.self.value.bias\", \"bert.encoder.layer.9.attention.output.dense.weight\", \"bert.encoder.layer.9.attention.output.dense.bias\", \"bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"bert.encoder.layer.9.intermediate.dense.weight\", \"bert.encoder.layer.9.intermediate.dense.bias\", \"bert.encoder.layer.9.output.dense.weight\", \"bert.encoder.layer.9.output.dense.bias\", \"bert.encoder.layer.9.output.LayerNorm.weight\", \"bert.encoder.layer.9.output.LayerNorm.bias\", \"bert.encoder.layer.10.attention.self.query.weight\", \"bert.encoder.layer.10.attention.self.query.bias\", \"bert.encoder.layer.10.attention.self.key.weight\", \"bert.encoder.layer.10.attention.self.key.bias\", \"bert.encoder.layer.10.attention.self.value.weight\", \"bert.encoder.layer.10.attention.self.value.bias\", \"bert.encoder.layer.10.attention.output.dense.weight\", \"bert.encoder.layer.10.attention.output.dense.bias\", \"bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"bert.encoder.layer.10.intermediate.dense.weight\", \"bert.encoder.layer.10.intermediate.dense.bias\", \"bert.encoder.layer.10.output.dense.weight\", \"bert.encoder.layer.10.output.dense.bias\", \"bert.encoder.layer.10.output.LayerNorm.weight\", \"bert.encoder.layer.10.output.LayerNorm.bias\", \"bert.encoder.layer.11.attention.self.query.weight\", \"bert.encoder.layer.11.attention.self.query.bias\", \"bert.encoder.layer.11.attention.self.key.weight\", \"bert.encoder.layer.11.attention.self.key.bias\", \"bert.encoder.layer.11.attention.self.value.weight\", \"bert.encoder.layer.11.attention.self.value.bias\", \"bert.encoder.layer.11.attention.output.dense.weight\", \"bert.encoder.layer.11.attention.output.dense.bias\", \"bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"bert.encoder.layer.11.intermediate.dense.weight\", \"bert.encoder.layer.11.intermediate.dense.bias\", \"bert.encoder.layer.11.output.dense.weight\", \"bert.encoder.layer.11.output.dense.bias\", \"bert.encoder.layer.11.output.LayerNorm.weight\", \"bert.encoder.layer.11.output.LayerNorm.bias\", \"bert.pooler.dense.weight\", \"bert.pooler.dense.bias\", \"classifier_1.weight\", \"classifier_1.bias\", \"classifier_2.weight\", \"classifier_2.bias\". \n\tUnexpected key(s) in state_dict: \"module.bert.embeddings.word_embeddings.weight\", \"module.bert.embeddings.position_embeddings.weight\", \"module.bert.embeddings.token_type_embeddings.weight\", \"module.bert.embeddings.LayerNorm.weight\", \"module.bert.embeddings.LayerNorm.bias\", \"module.bert.encoder.layer.0.attention.self.query.weight\", \"module.bert.encoder.layer.0.attention.self.query.bias\", \"module.bert.encoder.layer.0.attention.self.key.weight\", \"module.bert.encoder.layer.0.attention.self.key.bias\", \"module.bert.encoder.layer.0.attention.self.value.weight\", \"module.bert.encoder.layer.0.attention.self.value.bias\", \"module.bert.encoder.layer.0.attention.output.dense.weight\", \"module.bert.encoder.layer.0.attention.output.dense.bias\", \"module.bert.encoder.layer.0.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.0.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.0.intermediate.dense.weight\", \"module.bert.encoder.layer.0.intermediate.dense.bias\", \"module.bert.encoder.layer.0.output.dense.weight\", \"module.bert.encoder.layer.0.output.dense.bias\", \"module.bert.encoder.layer.0.output.LayerNorm.weight\", \"module.bert.encoder.layer.0.output.LayerNorm.bias\", \"module.bert.encoder.layer.1.attention.self.query.weight\", \"module.bert.encoder.layer.1.attention.self.query.bias\", \"module.bert.encoder.layer.1.attention.self.key.weight\", \"module.bert.encoder.layer.1.attention.self.key.bias\", \"module.bert.encoder.layer.1.attention.self.value.weight\", \"module.bert.encoder.layer.1.attention.self.value.bias\", \"module.bert.encoder.layer.1.attention.output.dense.weight\", \"module.bert.encoder.layer.1.attention.output.dense.bias\", \"module.bert.encoder.layer.1.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.1.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.1.intermediate.dense.weight\", \"module.bert.encoder.layer.1.intermediate.dense.bias\", \"module.bert.encoder.layer.1.output.dense.weight\", \"module.bert.encoder.layer.1.output.dense.bias\", \"module.bert.encoder.layer.1.output.LayerNorm.weight\", \"module.bert.encoder.layer.1.output.LayerNorm.bias\", \"module.bert.encoder.layer.2.attention.self.query.weight\", \"module.bert.encoder.layer.2.attention.self.query.bias\", \"module.bert.encoder.layer.2.attention.self.key.weight\", \"module.bert.encoder.layer.2.attention.self.key.bias\", \"module.bert.encoder.layer.2.attention.self.value.weight\", \"module.bert.encoder.layer.2.attention.self.value.bias\", \"module.bert.encoder.layer.2.attention.output.dense.weight\", \"module.bert.encoder.layer.2.attention.output.dense.bias\", \"module.bert.encoder.layer.2.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.2.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.2.intermediate.dense.weight\", \"module.bert.encoder.layer.2.intermediate.dense.bias\", \"module.bert.encoder.layer.2.output.dense.weight\", \"module.bert.encoder.layer.2.output.dense.bias\", \"module.bert.encoder.layer.2.output.LayerNorm.weight\", \"module.bert.encoder.layer.2.output.LayerNorm.bias\", \"module.bert.encoder.layer.3.attention.self.query.weight\", \"module.bert.encoder.layer.3.attention.self.query.bias\", \"module.bert.encoder.layer.3.attention.self.key.weight\", \"module.bert.encoder.layer.3.attention.self.key.bias\", \"module.bert.encoder.layer.3.attention.self.value.weight\", \"module.bert.encoder.layer.3.attention.self.value.bias\", \"module.bert.encoder.layer.3.attention.output.dense.weight\", \"module.bert.encoder.layer.3.attention.output.dense.bias\", \"module.bert.encoder.layer.3.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.3.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.3.intermediate.dense.weight\", \"module.bert.encoder.layer.3.intermediate.dense.bias\", \"module.bert.encoder.layer.3.output.dense.weight\", \"module.bert.encoder.layer.3.output.dense.bias\", \"module.bert.encoder.layer.3.output.LayerNorm.weight\", \"module.bert.encoder.layer.3.output.LayerNorm.bias\", \"module.bert.encoder.layer.4.attention.self.query.weight\", \"module.bert.encoder.layer.4.attention.self.query.bias\", \"module.bert.encoder.layer.4.attention.self.key.weight\", \"module.bert.encoder.layer.4.attention.self.key.bias\", \"module.bert.encoder.layer.4.attention.self.value.weight\", \"module.bert.encoder.layer.4.attention.self.value.bias\", \"module.bert.encoder.layer.4.attention.output.dense.weight\", \"module.bert.encoder.layer.4.attention.output.dense.bias\", \"module.bert.encoder.layer.4.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.4.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.4.intermediate.dense.weight\", \"module.bert.encoder.layer.4.intermediate.dense.bias\", \"module.bert.encoder.layer.4.output.dense.weight\", \"module.bert.encoder.layer.4.output.dense.bias\", \"module.bert.encoder.layer.4.output.LayerNorm.weight\", \"module.bert.encoder.layer.4.output.LayerNorm.bias\", \"module.bert.encoder.layer.5.attention.self.query.weight\", \"module.bert.encoder.layer.5.attention.self.query.bias\", \"module.bert.encoder.layer.5.attention.self.key.weight\", \"module.bert.encoder.layer.5.attention.self.key.bias\", \"module.bert.encoder.layer.5.attention.self.value.weight\", \"module.bert.encoder.layer.5.attention.self.value.bias\", \"module.bert.encoder.layer.5.attention.output.dense.weight\", \"module.bert.encoder.layer.5.attention.output.dense.bias\", \"module.bert.encoder.layer.5.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.5.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.5.intermediate.dense.weight\", \"module.bert.encoder.layer.5.intermediate.dense.bias\", \"module.bert.encoder.layer.5.output.dense.weight\", \"module.bert.encoder.layer.5.output.dense.bias\", \"module.bert.encoder.layer.5.output.LayerNorm.weight\", \"module.bert.encoder.layer.5.output.LayerNorm.bias\", \"module.bert.encoder.layer.6.attention.self.query.weight\", \"module.bert.encoder.layer.6.attention.self.query.bias\", \"module.bert.encoder.layer.6.attention.self.key.weight\", \"module.bert.encoder.layer.6.attention.self.key.bias\", \"module.bert.encoder.layer.6.attention.self.value.weight\", \"module.bert.encoder.layer.6.attention.self.value.bias\", \"module.bert.encoder.layer.6.attention.output.dense.weight\", \"module.bert.encoder.layer.6.attention.output.dense.bias\", \"module.bert.encoder.layer.6.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.6.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.6.intermediate.dense.weight\", \"module.bert.encoder.layer.6.intermediate.dense.bias\", \"module.bert.encoder.layer.6.output.dense.weight\", \"module.bert.encoder.layer.6.output.dense.bias\", \"module.bert.encoder.layer.6.output.LayerNorm.weight\", \"module.bert.encoder.layer.6.output.LayerNorm.bias\", \"module.bert.encoder.layer.7.attention.self.query.weight\", \"module.bert.encoder.layer.7.attention.self.query.bias\", \"module.bert.encoder.layer.7.attention.self.key.weight\", \"module.bert.encoder.layer.7.attention.self.key.bias\", \"module.bert.encoder.layer.7.attention.self.value.weight\", \"module.bert.encoder.layer.7.attention.self.value.bias\", \"module.bert.encoder.layer.7.attention.output.dense.weight\", \"module.bert.encoder.layer.7.attention.output.dense.bias\", \"module.bert.encoder.layer.7.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.7.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.7.intermediate.dense.weight\", \"module.bert.encoder.layer.7.intermediate.dense.bias\", \"module.bert.encoder.layer.7.output.dense.weight\", \"module.bert.encoder.layer.7.output.dense.bias\", \"module.bert.encoder.layer.7.output.LayerNorm.weight\", \"module.bert.encoder.layer.7.output.LayerNorm.bias\", \"module.bert.encoder.layer.8.attention.self.query.weight\", \"module.bert.encoder.layer.8.attention.self.query.bias\", \"module.bert.encoder.layer.8.attention.self.key.weight\", \"module.bert.encoder.layer.8.attention.self.key.bias\", \"module.bert.encoder.layer.8.attention.self.value.weight\", \"module.bert.encoder.layer.8.attention.self.value.bias\", \"module.bert.encoder.layer.8.attention.output.dense.weight\", \"module.bert.encoder.layer.8.attention.output.dense.bias\", \"module.bert.encoder.layer.8.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.8.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.8.intermediate.dense.weight\", \"module.bert.encoder.layer.8.intermediate.dense.bias\", \"module.bert.encoder.layer.8.output.dense.weight\", \"module.bert.encoder.layer.8.output.dense.bias\", \"module.bert.encoder.layer.8.output.LayerNorm.weight\", \"module.bert.encoder.layer.8.output.LayerNorm.bias\", \"module.bert.encoder.layer.9.attention.self.query.weight\", \"module.bert.encoder.layer.9.attention.self.query.bias\", \"module.bert.encoder.layer.9.attention.self.key.weight\", \"module.bert.encoder.layer.9.attention.self.key.bias\", \"module.bert.encoder.layer.9.attention.self.value.weight\", \"module.bert.encoder.layer.9.attention.self.value.bias\", \"module.bert.encoder.layer.9.attention.output.dense.weight\", \"module.bert.encoder.layer.9.attention.output.dense.bias\", \"module.bert.encoder.layer.9.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.9.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.9.intermediate.dense.weight\", \"module.bert.encoder.layer.9.intermediate.dense.bias\", \"module.bert.encoder.layer.9.output.dense.weight\", \"module.bert.encoder.layer.9.output.dense.bias\", \"module.bert.encoder.layer.9.output.LayerNorm.weight\", \"module.bert.encoder.layer.9.output.LayerNorm.bias\", \"module.bert.encoder.layer.10.attention.self.query.weight\", \"module.bert.encoder.layer.10.attention.self.query.bias\", \"module.bert.encoder.layer.10.attention.self.key.weight\", \"module.bert.encoder.layer.10.attention.self.key.bias\", \"module.bert.encoder.layer.10.attention.self.value.weight\", \"module.bert.encoder.layer.10.attention.self.value.bias\", \"module.bert.encoder.layer.10.attention.output.dense.weight\", \"module.bert.encoder.layer.10.attention.output.dense.bias\", \"module.bert.encoder.layer.10.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.10.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.10.intermediate.dense.weight\", \"module.bert.encoder.layer.10.intermediate.dense.bias\", \"module.bert.encoder.layer.10.output.dense.weight\", \"module.bert.encoder.layer.10.output.dense.bias\", \"module.bert.encoder.layer.10.output.LayerNorm.weight\", \"module.bert.encoder.layer.10.output.LayerNorm.bias\", \"module.bert.encoder.layer.11.attention.self.query.weight\", \"module.bert.encoder.layer.11.attention.self.query.bias\", \"module.bert.encoder.layer.11.attention.self.key.weight\", \"module.bert.encoder.layer.11.attention.self.key.bias\", \"module.bert.encoder.layer.11.attention.self.value.weight\", \"module.bert.encoder.layer.11.attention.self.value.bias\", \"module.bert.encoder.layer.11.attention.output.dense.weight\", \"module.bert.encoder.layer.11.attention.output.dense.bias\", \"module.bert.encoder.layer.11.attention.output.LayerNorm.weight\", \"module.bert.encoder.layer.11.attention.output.LayerNorm.bias\", \"module.bert.encoder.layer.11.intermediate.dense.weight\", \"module.bert.encoder.layer.11.intermediate.dense.bias\", \"module.bert.encoder.layer.11.output.dense.weight\", \"module.bert.encoder.layer.11.output.dense.bias\", \"module.bert.encoder.layer.11.output.LayerNorm.weight\", \"module.bert.encoder.layer.11.output.LayerNorm.bias\", \"module.bert.pooler.dense.weight\", \"module.bert.pooler.dense.bias\", \"module.classifier.weight\", \"module.classifier.bias\". "
     ]
    }
   ],
   "source": [
    "MAX_LEN = 210\n",
    "bs = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count(); \n",
    "logging.info(\"GPUs Detected: %s\" % (n_gpu))\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(opt[\"model\"], do_lower_case=False);\n",
    "# Model Initialize\n",
    "model = BertForTokenClassification.from_pretrained(opt[\"model\"], num_labels=opt[\"nLabels\"]);\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(opt[\"loadModel\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(index, predictions, tokenized_texts, test = True, val_tags=None):\n",
    "    print('Sentence: '+' '.join(tokenized_texts[index]))\n",
    "    pred_l = [predictions[index][i] for i in range(len(predictions[index])) if predictions[index][i] not in [hash_token, end_token]]\n",
    "    pred_l = max(pred_l)\n",
    "    if not test:\n",
    "        truth = [i for i in range(len(val_tags[index])) if val_tags[index][i] not in [hash_token, end_token, 0]]\n",
    "        truth_l = [val_tags[index][i] for i in range(len(val_tags[index])) if val_tags[index][i] not in [hash_token, end_token]]\n",
    "        truth_l = max(truth_l)\n",
    "        gold = [tokenized_texts[index][i] for i in truth]\n",
    "        print('Truth label: ',truth_l, ' Predicted label: ',pred_l)\n",
    "        print('Porpaganda Sequence: '+' '.join(gold))\n",
    " \n",
    "    \n",
    "    pred = [i for i in range(len(predictions[index])) if predictions[index][i] not in [hash_token, end_token, 0]]\n",
    "    \n",
    "    if pred:\n",
    "        if test:\n",
    "            print(len(predictions))\n",
    "            print(predictions)\n",
    "            #print([tag_t.get(predictions[0][x]) for x in predictions[0]])\n",
    "        predicted = [tokenized_texts[index][i] for i in pred]\n",
    "        print('Predicted Sequence: '+' '.join(predicted))\n",
    "        #print(predictions)\n",
    "    else:\n",
    "        print(\"No propaganda detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-bd896be18a26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenized_texts' is not defined"
     ]
    }
   ],
   "source": [
    "visualize(4, predictions, tokenized_texts, False, val_tags.detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sentence(sample):\n",
    "    sample = sample.split()\n",
    "    clean = [[tokenizer.tokenize(words) for words in sent] for sent in [sample]] \n",
    "    tokenize = [concatenate_list_data(sent) for sent in clean]\n",
    "    numerics = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenize],\n",
    "                          max_len=opt[\"maxLen\"])\n",
    "    attention_masks = [[float(i>0) for i in ii] for ii in numerics]\n",
    "    input_sample = torch.tensor(numerics)\n",
    "    input_mask = torch.tensor(attention_masks)\n",
    "    model.eval()\n",
    "    logits = model(input_sample, token_type_ids=None,\n",
    "                       attention_mask=input_mask)\n",
    "    predictions_sample = []\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    predictions_sample.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "    visualize(0, predictions_sample, tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Trump is a piece of trash .\n",
      "1\n",
      "[[0, 0, 0, 9, 9, 9, 0, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]]\n",
      "Predicted Sequence: piece of trash\n"
     ]
    }
   ],
   "source": [
    "test_sentence('Trump is a piece of trash.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = df.loc[df['ID'] == df[\"ID\"][x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "strPath = \"datasets-v5/tasks-2-3/test/article\"+df[\"ID\"][x]+\".txt\"\n",
    "\n",
    "f = open(strPath)\n",
    "\n",
    "strText = f.read()\n",
    "\n",
    "docs = {\"text\":strText,\n",
    "       \"ents\":[],\n",
    "       \"title\":None}\n",
    "\n",
    "for index, row in viz.iterrows():\n",
    "    docs[\"ents\"].append({\"start\":row[2], \"end\":row[3], \"label\":row[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Facebook Bans Outline to Stop Jihadi \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Attacks on Americans\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Flag-Waving</span>\n",
       "</mark>\n",
       ".</br></br>[Editors' note: To best understand why Facebook would ban Jamie Glazov on 9/11 for his article on how to best prevent more 9/11s, pre-order Jamie's new book, Jihadist Psychopath: How He Is Charming, Seducing, and Devouring Us: HERE.</br>The book illustrates how \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the Jihadist Psychopath\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Name_Calling,Labeling</span>\n",
       "</mark>\n",
       " has successfully built his totalitarian plantation -- on which many in the West are now enslaved and dutifully following his orders.</br>Jamie outlines the frameworks of this \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    tyrannical plantation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Loaded_Language</span>\n",
       "</mark>\n",
       " and how those who are trapped on it, and yearn for freedom, can best escape.]</br>Reprinted from WND.com.</br>Somewhere in the “community standards” that Facebook demands everyone follow is a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    real doozy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Loaded_Language</span>\n",
       "</mark>\n",
       ".</br>The social-media company has told author and commentator Jamie Glazov that their standards forbid his article about how to prevent jihadi attacks on Americans.</br>It’s all about Glazov’s new book, “\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Jihadist Psychopath\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Name_Calling,Labeling</span>\n",
       "</mark>\n",
       ": How He Is Charming, Seducing, and Devouring Us.”</br>At FrontPage Magazine, where he is editor, he had posted “9 Steps to Successfully Counter Jihad,” which included recommendations such as “Label the enemy and make a threat assessment” and “Stop ‘partnering’ with Muslim Brotherhood front groups.”</br>That apparently was too much for Facebook, which declared “only you can see this post” because it “goes against our Community Standards.”</br>He was suspended from Facebook for 30 days on Sept. 11, the anniversary of the Islamic jihadist attack on America that killed nearly 3,000.</br>Glazov told Breitbart, “This is \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    really getting surreal in the creepiest and most harrowing Stalinist sense\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Loaded_Language</span>\n",
       "</mark>\n",
       ".”</br></br>FrontPage Magazine reported:</br>Facebook’s \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Unholy Alliance masters\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Name_Calling,Labeling</span>\n",
       "</mark>\n",
       " are, without doubt, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    accelerating their totalitarian suffocation of free thought\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Loaded_Language</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    expression\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Loaded_Language</span>\n",
       "</mark>\n",
       ".</br>It is no surprise, therefore, that Frontpage’s editor, and host of ‘The Glazov Gang,’ was suspended from Facebook for 30 days yesterday, on September 11, after posting his article, ‘9 Steps to Successfully Counter Jihad.’ Glazov believed that the article was more relevant and urgent than ever due to the skyrocketing jihadist \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    stabbings\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Loaded_Language</span>\n",
       "</mark>\n",
       " in Europe — and to the 17th anniversary of 9/11 that was approaching the next day.</br>The report said it appears “that daring to give suggestions on how our civilization can stop jihadist attacks and another 9/11 is against Facebook’s ‘community standards.</br>'”</br>“Glazov’s advice also involves the promotion of supporting moderate Muslims – a move that is, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    clearly, horrifying to Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Loaded_Language</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    ’s masters\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Name_Calling,Labeling</span>\n",
       "</mark>\n",
       " and therefore also violates their ‘community standards,'” the report said.</br>No doubt, Glazov’s consistent campaigning on behalf of Muslim women and girls in his efforts to protect them from FGM, honor killings and other Shariah barbarities, has gained him the anger and hatred of Facebook’s guardians — who are clearly on the side of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the Shariah enforcers and oppressors of Muslim women\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Name_Calling,Labeling</span>\n",
       "</mark>\n",
       " and girls.</br>The report recalls that Facebook censored Glazov in April for posting screenshots of a Muslim’s threat to him.</br>Twitter also lashed \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    out\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Loaded_Language</span>\n",
       "</mark>\n",
       " at him for quoting directly from Islamic religious texts, citing its anti-“hate” policies.</br>It is ‘\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    hateful conduct\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Loaded_Language</span>\n",
       "</mark>\n",
       ",’ apparently, to reference what Islamic texts themselves say.</br>Indeed, Frontpage’s editor had simply referred to Sahih Bukhari’s texts discussing Mohammed’s marriage to Aisha when she was six years old (7.62.88) and to Quranic Suras that mandate the Hijab for women (24:31; 33:59) and sanction sexual slavery (4:3; 33:50).</br>Facebook also refused to respond to Glazov’s inquiry about “what it is specifically that violates Facebook’s ‘community standards’ when a person gives advice on how to best defend American lives from jihad.”</br>Glazov has written about the subject in previous books, including “High Noon for America: The Coming Showdown” and “United in Hate.”</br>In his “9 Steps” article, he points out that the Obama administration was “cooperating with, and listening to, Muslim Brotherhood front groups such as CAIR and ISNA.”</br>The government needs, he said, to “implement a concrete ‘countering-jihad’ strategy.”</br>And he said it needs to affirm “Shariah’s assault on the U.S. Constitution as seditious.”</br>A last key point, the said, is to ridicule the enemy.</br>Ridicule is a vicious and potent weapon.</br>There is a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    baffling and shameful silence\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Loaded_Language</span>\n",
       "</mark>\n",
       " in our culture’s sphere of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    comedy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Loaded_Language</span>\n",
       "</mark>\n",
       ", especially in Hollywood and our media, with regard to the myriad ingredients of Shariah and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    jihad\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Loaded_Language</span>\n",
       "</mark>\n",
       " that merit at least a million \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    hilarious satirical sketches\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Loaded_Language</span>\n",
       "</mark>\n",
       ".</br>Bill Maher, for whatever \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    unappealing drawbacks\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Loaded_Language</span>\n",
       "</mark>\n",
       " he has in conservatives’ eyes, has set a bold standard in this respect in his Burka Fashion Show skit.</br>American comedians need to start writing scripts that follow in Maher’s footsteps and Americans need to encourage and equip them to do so – and to also vigorously defend them from the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    attacks and slanders\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Appeal_to_fear-prejudice</span>\n",
       "</mark>\n",
       " they will \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    inevitably\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Appeal_to_fear-prejudice</span>\n",
       "</mark>\n",
       " receive \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    from totalitarian leftist and Islamic forces\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Appeal_to_fear-prejudice</span>\n",
       "</mark>\n",
       ".\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(docs, style=\"ent\", manual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
